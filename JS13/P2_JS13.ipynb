{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96bbd114",
   "metadata": {},
   "source": [
    "# JS13 - Artificial Neural Network (ANN) dan Evaluasi Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7342c0d1",
   "metadata": {},
   "source": [
    "## Praktikum 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4967387c",
   "metadata": {},
   "source": [
    "Langkah :\n",
    "1. Import library.\n",
    "2. Load dataset.\n",
    "3. Bangun model.\n",
    "4. Kompilasi dan latih model.\n",
    "5. Evaluasi hasil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20bea378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.76.0-cp313-cp313-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.12.1)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.4-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: pillow in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.1.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.18.0-cp313-cp313-win_amd64.whl.metadata (35 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl (332.0 MB)\n",
      "   ---------------------------------------- 0.0/332.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/332.0 MB 8.2 MB/s eta 0:00:41\n",
      "   ---------------------------------------- 3.1/332.0 MB 8.8 MB/s eta 0:00:38\n",
      "    --------------------------------------- 5.0/332.0 MB 9.1 MB/s eta 0:00:37\n",
      "    --------------------------------------- 7.1/332.0 MB 9.2 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 9.2/332.0 MB 9.7 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 11.5/332.0 MB 9.7 MB/s eta 0:00:33\n",
      "   - -------------------------------------- 12.8/332.0 MB 9.5 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 13.6/332.0 MB 8.9 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 15.5/332.0 MB 8.7 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 17.0/332.0 MB 8.4 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 18.6/332.0 MB 8.2 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 19.9/332.0 MB 8.0 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 21.2/332.0 MB 8.0 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 22.8/332.0 MB 7.9 MB/s eta 0:00:40\n",
      "   -- ------------------------------------- 24.4/332.0 MB 7.9 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 26.0/332.0 MB 7.9 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 27.3/332.0 MB 7.7 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 28.6/332.0 MB 7.6 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 29.9/332.0 MB 7.6 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 31.2/332.0 MB 7.5 MB/s eta 0:00:41\n",
      "   --- ------------------------------------ 32.2/332.0 MB 7.4 MB/s eta 0:00:41\n",
      "   ---- ----------------------------------- 33.8/332.0 MB 7.4 MB/s eta 0:00:41\n",
      "   ---- ----------------------------------- 35.4/332.0 MB 7.4 MB/s eta 0:00:41\n",
      "   ---- ----------------------------------- 36.7/332.0 MB 7.3 MB/s eta 0:00:41\n",
      "   ---- ----------------------------------- 38.3/332.0 MB 7.3 MB/s eta 0:00:41\n",
      "   ---- ----------------------------------- 39.3/332.0 MB 7.3 MB/s eta 0:00:41\n",
      "   ---- ----------------------------------- 40.9/332.0 MB 7.3 MB/s eta 0:00:41\n",
      "   ----- ---------------------------------- 42.5/332.0 MB 7.3 MB/s eta 0:00:40\n",
      "   ----- ---------------------------------- 43.8/332.0 MB 7.2 MB/s eta 0:00:40\n",
      "   ----- ---------------------------------- 45.1/332.0 MB 7.2 MB/s eta 0:00:40\n",
      "   ----- ---------------------------------- 46.4/332.0 MB 7.2 MB/s eta 0:00:40\n",
      "   ----- ---------------------------------- 48.0/332.0 MB 7.2 MB/s eta 0:00:40\n",
      "   ----- ---------------------------------- 49.0/332.0 MB 7.1 MB/s eta 0:00:40\n",
      "   ------ --------------------------------- 50.6/332.0 MB 7.1 MB/s eta 0:00:40\n",
      "   ------ --------------------------------- 51.6/332.0 MB 7.2 MB/s eta 0:00:40\n",
      "   ------ --------------------------------- 53.2/332.0 MB 7.1 MB/s eta 0:00:40\n",
      "   ------ --------------------------------- 54.3/332.0 MB 7.1 MB/s eta 0:00:40\n",
      "   ------ --------------------------------- 55.3/332.0 MB 6.9 MB/s eta 0:00:40\n",
      "   ------ --------------------------------- 56.1/332.0 MB 6.9 MB/s eta 0:00:41\n",
      "   ------ --------------------------------- 57.1/332.0 MB 6.8 MB/s eta 0:00:41\n",
      "   ------ --------------------------------- 57.9/332.0 MB 6.7 MB/s eta 0:00:41\n",
      "   ------- -------------------------------- 59.0/332.0 MB 6.7 MB/s eta 0:00:41\n",
      "   ------- -------------------------------- 59.8/332.0 MB 6.6 MB/s eta 0:00:41\n",
      "   ------- -------------------------------- 61.1/332.0 MB 6.6 MB/s eta 0:00:42\n",
      "   ------- -------------------------------- 62.1/332.0 MB 6.6 MB/s eta 0:00:42\n",
      "   ------- -------------------------------- 63.2/332.0 MB 6.5 MB/s eta 0:00:42\n",
      "   ------- -------------------------------- 64.2/332.0 MB 6.5 MB/s eta 0:00:42\n",
      "   ------- -------------------------------- 65.5/332.0 MB 6.5 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 66.6/332.0 MB 6.5 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 67.4/332.0 MB 6.4 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 68.7/332.0 MB 6.4 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 69.7/332.0 MB 6.4 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 70.8/332.0 MB 6.3 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 71.6/332.0 MB 6.3 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 72.9/332.0 MB 6.3 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 73.9/332.0 MB 6.3 MB/s eta 0:00:42\n",
      "   --------- ------------------------------ 75.0/332.0 MB 6.2 MB/s eta 0:00:42\n",
      "   --------- ------------------------------ 76.0/332.0 MB 6.2 MB/s eta 0:00:42\n",
      "   --------- ------------------------------ 77.1/332.0 MB 6.2 MB/s eta 0:00:42\n",
      "   --------- ------------------------------ 78.4/332.0 MB 6.2 MB/s eta 0:00:42\n",
      "   --------- ------------------------------ 79.4/332.0 MB 6.2 MB/s eta 0:00:41\n",
      "   --------- ------------------------------ 80.7/332.0 MB 6.1 MB/s eta 0:00:41\n",
      "   --------- ------------------------------ 81.8/332.0 MB 6.1 MB/s eta 0:00:41\n",
      "   ---------- ----------------------------- 83.1/332.0 MB 6.1 MB/s eta 0:00:41\n",
      "   ---------- ----------------------------- 84.4/332.0 MB 6.1 MB/s eta 0:00:41\n",
      "   ---------- ----------------------------- 85.5/332.0 MB 6.1 MB/s eta 0:00:41\n",
      "   ---------- ----------------------------- 86.8/332.0 MB 6.1 MB/s eta 0:00:41\n",
      "   ---------- ----------------------------- 87.8/332.0 MB 6.1 MB/s eta 0:00:40\n",
      "   ---------- ----------------------------- 88.9/332.0 MB 6.1 MB/s eta 0:00:41\n",
      "   ---------- ----------------------------- 89.7/332.0 MB 6.0 MB/s eta 0:00:41\n",
      "   ---------- ----------------------------- 90.4/332.0 MB 6.0 MB/s eta 0:00:41\n",
      "   ---------- ----------------------------- 91.0/332.0 MB 6.0 MB/s eta 0:00:41\n",
      "   ----------- ---------------------------- 91.5/332.0 MB 5.9 MB/s eta 0:00:41\n",
      "   ----------- ---------------------------- 92.0/332.0 MB 5.9 MB/s eta 0:00:41\n",
      "   ----------- ---------------------------- 92.5/332.0 MB 5.8 MB/s eta 0:00:42\n",
      "   ----------- ---------------------------- 93.1/332.0 MB 5.8 MB/s eta 0:00:42\n",
      "   ----------- ---------------------------- 93.6/332.0 MB 5.7 MB/s eta 0:00:42\n",
      "   ----------- ---------------------------- 94.1/332.0 MB 5.7 MB/s eta 0:00:42\n",
      "   ----------- ---------------------------- 94.9/332.0 MB 5.7 MB/s eta 0:00:42\n",
      "   ----------- ---------------------------- 95.4/332.0 MB 5.6 MB/s eta 0:00:42\n",
      "   ----------- ---------------------------- 95.9/332.0 MB 5.6 MB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 96.2/332.0 MB 5.6 MB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 96.7/332.0 MB 5.5 MB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 97.0/332.0 MB 5.5 MB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 97.5/332.0 MB 5.4 MB/s eta 0:00:44\n",
      "   ----------- ---------------------------- 97.8/332.0 MB 5.4 MB/s eta 0:00:44\n",
      "   ----------- ---------------------------- 98.0/332.0 MB 5.4 MB/s eta 0:00:44\n",
      "   ----------- ---------------------------- 98.6/332.0 MB 5.3 MB/s eta 0:00:45\n",
      "   ----------- ---------------------------- 98.8/332.0 MB 5.3 MB/s eta 0:00:45\n",
      "   ----------- ---------------------------- 99.1/332.0 MB 5.2 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 99.6/332.0 MB 5.2 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 99.9/332.0 MB 5.1 MB/s eta 0:00:46\n",
      "   ------------ --------------------------- 100.1/332.0 MB 5.1 MB/s eta 0:00:46\n",
      "   ------------ --------------------------- 100.7/332.0 MB 5.1 MB/s eta 0:00:46\n",
      "   ------------ --------------------------- 100.9/332.0 MB 5.0 MB/s eta 0:00:46\n",
      "   ------------ --------------------------- 101.4/332.0 MB 5.0 MB/s eta 0:00:47\n",
      "   ------------ --------------------------- 101.7/332.0 MB 5.0 MB/s eta 0:00:47\n",
      "   ------------ --------------------------- 102.2/332.0 MB 4.9 MB/s eta 0:00:47\n",
      "   ------------ --------------------------- 102.8/332.0 MB 4.9 MB/s eta 0:00:47\n",
      "   ------------ --------------------------- 103.3/332.0 MB 4.9 MB/s eta 0:00:47\n",
      "   ------------ --------------------------- 103.5/332.0 MB 4.8 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 103.8/332.0 MB 4.8 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 104.3/332.0 MB 4.8 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 104.9/332.0 MB 4.8 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 105.1/332.0 MB 4.7 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 105.6/332.0 MB 4.7 MB/s eta 0:00:49\n",
      "   ------------ --------------------------- 106.2/332.0 MB 4.7 MB/s eta 0:00:49\n",
      "   ------------ --------------------------- 106.7/332.0 MB 4.7 MB/s eta 0:00:49\n",
      "   ------------ --------------------------- 107.2/332.0 MB 4.6 MB/s eta 0:00:49\n",
      "   ------------ --------------------------- 107.7/332.0 MB 4.6 MB/s eta 0:00:49\n",
      "   ------------- -------------------------- 108.3/332.0 MB 4.6 MB/s eta 0:00:49\n",
      "   ------------- -------------------------- 109.1/332.0 MB 4.6 MB/s eta 0:00:49\n",
      "   ------------- -------------------------- 109.6/332.0 MB 4.6 MB/s eta 0:00:49\n",
      "   ------------- -------------------------- 110.4/332.0 MB 4.6 MB/s eta 0:00:49\n",
      "   ------------- -------------------------- 111.1/332.0 MB 4.5 MB/s eta 0:00:49\n",
      "   ------------- -------------------------- 111.7/332.0 MB 4.5 MB/s eta 0:00:49\n",
      "   ------------- -------------------------- 112.5/332.0 MB 4.5 MB/s eta 0:00:49\n",
      "   ------------- -------------------------- 113.2/332.0 MB 4.5 MB/s eta 0:00:49\n",
      "   ------------- -------------------------- 114.0/332.0 MB 4.5 MB/s eta 0:00:49\n",
      "   ------------- -------------------------- 114.8/332.0 MB 4.5 MB/s eta 0:00:49\n",
      "   ------------- -------------------------- 115.6/332.0 MB 4.5 MB/s eta 0:00:49\n",
      "   -------------- ------------------------- 116.4/332.0 MB 4.5 MB/s eta 0:00:49\n",
      "   -------------- ------------------------- 116.7/332.0 MB 4.5 MB/s eta 0:00:49\n",
      "   -------------- ------------------------- 117.2/332.0 MB 4.5 MB/s eta 0:00:49\n",
      "   -------------- ------------------------- 117.7/332.0 MB 4.4 MB/s eta 0:00:49\n",
      "   -------------- ------------------------- 118.2/332.0 MB 4.4 MB/s eta 0:00:49\n",
      "   -------------- ------------------------- 118.8/332.0 MB 4.4 MB/s eta 0:00:49\n",
      "   -------------- ------------------------- 119.3/332.0 MB 4.4 MB/s eta 0:00:49\n",
      "   -------------- ------------------------- 120.1/332.0 MB 4.4 MB/s eta 0:00:49\n",
      "   -------------- ------------------------- 120.6/332.0 MB 4.4 MB/s eta 0:00:49\n",
      "   -------------- ------------------------- 121.4/332.0 MB 4.4 MB/s eta 0:00:49\n",
      "   -------------- ------------------------- 121.9/332.0 MB 4.3 MB/s eta 0:00:49\n",
      "   -------------- ------------------------- 122.7/332.0 MB 4.3 MB/s eta 0:00:49\n",
      "   -------------- ------------------------- 123.2/332.0 MB 4.3 MB/s eta 0:00:49\n",
      "   -------------- ------------------------- 123.7/332.0 MB 4.3 MB/s eta 0:00:49\n",
      "   -------------- ------------------------- 124.3/332.0 MB 4.3 MB/s eta 0:00:49\n",
      "   --------------- ------------------------ 125.0/332.0 MB 4.3 MB/s eta 0:00:49\n",
      "   --------------- ------------------------ 125.6/332.0 MB 4.3 MB/s eta 0:00:49\n",
      "   --------------- ------------------------ 126.1/332.0 MB 4.3 MB/s eta 0:00:49\n",
      "   --------------- ------------------------ 126.6/332.0 MB 4.2 MB/s eta 0:00:49\n",
      "   --------------- ------------------------ 127.1/332.0 MB 4.2 MB/s eta 0:00:49\n",
      "   --------------- ------------------------ 127.7/332.0 MB 4.2 MB/s eta 0:00:49\n",
      "   --------------- ------------------------ 127.9/332.0 MB 4.2 MB/s eta 0:00:50\n",
      "   --------------- ------------------------ 128.2/332.0 MB 4.1 MB/s eta 0:00:50\n",
      "   --------------- ------------------------ 128.7/332.0 MB 4.0 MB/s eta 0:00:51\n",
      "   --------------- ------------------------ 129.0/332.0 MB 4.0 MB/s eta 0:00:52\n",
      "   --------------- ------------------------ 129.2/332.0 MB 3.9 MB/s eta 0:00:52\n",
      "   --------------- ------------------------ 129.8/332.0 MB 3.9 MB/s eta 0:00:53\n",
      "   --------------- ------------------------ 130.0/332.0 MB 3.9 MB/s eta 0:00:53\n",
      "   --------------- ------------------------ 130.3/332.0 MB 3.8 MB/s eta 0:00:53\n",
      "   --------------- ------------------------ 130.8/332.0 MB 3.8 MB/s eta 0:00:54\n",
      "   --------------- ------------------------ 131.1/332.0 MB 3.8 MB/s eta 0:00:54\n",
      "   --------------- ------------------------ 131.6/332.0 MB 3.7 MB/s eta 0:00:54\n",
      "   --------------- ------------------------ 132.1/332.0 MB 3.7 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 132.4/332.0 MB 3.6 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 132.6/332.0 MB 3.6 MB/s eta 0:00:56\n",
      "   ---------------- ----------------------- 133.2/332.0 MB 3.5 MB/s eta 0:00:57\n",
      "   ---------------- ----------------------- 133.4/332.0 MB 3.5 MB/s eta 0:00:57\n",
      "   ---------------- ----------------------- 133.7/332.0 MB 3.5 MB/s eta 0:00:57\n",
      "   ---------------- ----------------------- 133.7/332.0 MB 3.5 MB/s eta 0:00:57\n",
      "   ---------------- ----------------------- 134.0/332.0 MB 3.4 MB/s eta 0:00:58\n",
      "   ---------------- ----------------------- 134.2/332.0 MB 3.4 MB/s eta 0:00:59\n",
      "   ---------------- ----------------------- 134.7/332.0 MB 3.3 MB/s eta 0:01:00\n",
      "   ---------------- ----------------------- 135.0/332.0 MB 3.3 MB/s eta 0:01:00\n",
      "   ---------------- ----------------------- 135.5/332.0 MB 3.3 MB/s eta 0:01:01\n",
      "   ---------------- ----------------------- 135.8/332.0 MB 3.2 MB/s eta 0:01:01\n",
      "   ---------------- ----------------------- 136.3/332.0 MB 3.2 MB/s eta 0:01:01\n",
      "   ---------------- ----------------------- 136.8/332.0 MB 3.2 MB/s eta 0:01:02\n",
      "   ---------------- ----------------------- 137.4/332.0 MB 3.1 MB/s eta 0:01:02\n",
      "   ---------------- ----------------------- 137.9/332.0 MB 3.1 MB/s eta 0:01:03\n",
      "   ---------------- ----------------------- 138.7/332.0 MB 3.1 MB/s eta 0:01:03\n",
      "   ---------------- ----------------------- 139.2/332.0 MB 3.1 MB/s eta 0:01:03\n",
      "   ---------------- ----------------------- 139.7/332.0 MB 3.0 MB/s eta 0:01:04\n",
      "   ---------------- ----------------------- 140.2/332.0 MB 3.0 MB/s eta 0:01:04\n",
      "   ---------------- ----------------------- 141.0/332.0 MB 3.0 MB/s eta 0:01:05\n",
      "   ----------------- ---------------------- 141.8/332.0 MB 3.0 MB/s eta 0:01:05\n",
      "   ----------------- ---------------------- 142.3/332.0 MB 3.0 MB/s eta 0:01:05\n",
      "   ----------------- ---------------------- 143.1/332.0 MB 2.9 MB/s eta 0:01:05\n",
      "   ----------------- ---------------------- 143.9/332.0 MB 2.9 MB/s eta 0:01:05\n",
      "   ----------------- ---------------------- 144.4/332.0 MB 2.9 MB/s eta 0:01:05\n",
      "   ----------------- ---------------------- 145.0/332.0 MB 2.9 MB/s eta 0:01:05\n",
      "   ----------------- ---------------------- 145.8/332.0 MB 2.9 MB/s eta 0:01:05\n",
      "   ----------------- ---------------------- 146.3/332.0 MB 2.9 MB/s eta 0:01:05\n",
      "   ----------------- ---------------------- 146.8/332.0 MB 2.9 MB/s eta 0:01:05\n",
      "   ----------------- ---------------------- 147.6/332.0 MB 2.9 MB/s eta 0:01:05\n",
      "   ----------------- ---------------------- 148.4/332.0 MB 2.9 MB/s eta 0:01:05\n",
      "   ----------------- ---------------------- 148.9/332.0 MB 2.8 MB/s eta 0:01:05\n",
      "   ------------------ --------------------- 149.7/332.0 MB 2.8 MB/s eta 0:01:05\n",
      "   ------------------ --------------------- 150.5/332.0 MB 2.8 MB/s eta 0:01:05\n",
      "   ------------------ --------------------- 151.3/332.0 MB 2.8 MB/s eta 0:01:05\n",
      "   ------------------ --------------------- 151.8/332.0 MB 2.8 MB/s eta 0:01:05\n",
      "   ------------------ --------------------- 152.3/332.0 MB 2.8 MB/s eta 0:01:05\n",
      "   ------------------ --------------------- 153.1/332.0 MB 2.8 MB/s eta 0:01:05\n",
      "   ------------------ --------------------- 153.4/332.0 MB 2.7 MB/s eta 0:01:06\n",
      "   ------------------ --------------------- 153.9/332.0 MB 2.7 MB/s eta 0:01:06\n",
      "   ------------------ --------------------- 154.1/332.0 MB 2.7 MB/s eta 0:01:06\n",
      "   ------------------ --------------------- 154.7/332.0 MB 2.7 MB/s eta 0:01:07\n",
      "   ------------------ --------------------- 155.2/332.0 MB 2.7 MB/s eta 0:01:07\n",
      "   ------------------ --------------------- 155.7/332.0 MB 2.6 MB/s eta 0:01:07\n",
      "   ------------------ --------------------- 156.2/332.0 MB 2.6 MB/s eta 0:01:07\n",
      "   ------------------ --------------------- 157.0/332.0 MB 2.6 MB/s eta 0:01:08\n",
      "   ------------------ --------------------- 157.5/332.0 MB 2.6 MB/s eta 0:01:08\n",
      "   ------------------- -------------------- 158.1/332.0 MB 2.6 MB/s eta 0:01:08\n",
      "   ------------------- -------------------- 158.9/332.0 MB 2.5 MB/s eta 0:01:09\n",
      "   ------------------- -------------------- 159.4/332.0 MB 2.5 MB/s eta 0:01:09\n",
      "   ------------------- -------------------- 160.2/332.0 MB 2.5 MB/s eta 0:01:09\n",
      "   ------------------- -------------------- 161.0/332.0 MB 2.5 MB/s eta 0:01:09\n",
      "   ------------------- -------------------- 161.5/332.0 MB 2.5 MB/s eta 0:01:09\n",
      "   ------------------- -------------------- 162.0/332.0 MB 2.5 MB/s eta 0:01:09\n",
      "   ------------------- -------------------- 162.5/332.0 MB 2.5 MB/s eta 0:01:09\n",
      "   ------------------- -------------------- 163.3/332.0 MB 2.4 MB/s eta 0:01:09\n",
      "   ------------------- -------------------- 164.1/332.0 MB 2.4 MB/s eta 0:01:09\n",
      "   ------------------- -------------------- 164.6/332.0 MB 2.4 MB/s eta 0:01:09\n",
      "   ------------------- -------------------- 165.4/332.0 MB 2.5 MB/s eta 0:01:08\n",
      "   -------------------- ------------------- 166.2/332.0 MB 2.5 MB/s eta 0:01:08\n",
      "   -------------------- ------------------- 167.0/332.0 MB 2.5 MB/s eta 0:01:07\n",
      "   -------------------- ------------------- 167.8/332.0 MB 2.5 MB/s eta 0:01:07\n",
      "   -------------------- ------------------- 168.3/332.0 MB 2.5 MB/s eta 0:01:06\n",
      "   -------------------- ------------------- 169.3/332.0 MB 2.5 MB/s eta 0:01:06\n",
      "   -------------------- ------------------- 170.1/332.0 MB 2.5 MB/s eta 0:01:05\n",
      "   -------------------- ------------------- 170.9/332.0 MB 2.5 MB/s eta 0:01:05\n",
      "   -------------------- ------------------- 171.7/332.0 MB 2.5 MB/s eta 0:01:04\n",
      "   -------------------- ------------------- 172.8/332.0 MB 2.5 MB/s eta 0:01:03\n",
      "   -------------------- ------------------- 173.5/332.0 MB 2.6 MB/s eta 0:01:02\n",
      "   --------------------- ------------------ 174.6/332.0 MB 2.6 MB/s eta 0:01:02\n",
      "   --------------------- ------------------ 175.6/332.0 MB 2.6 MB/s eta 0:01:01\n",
      "   --------------------- ------------------ 176.4/332.0 MB 2.6 MB/s eta 0:01:00\n",
      "   --------------------- ------------------ 177.2/332.0 MB 2.6 MB/s eta 0:00:59\n",
      "   --------------------- ------------------ 178.0/332.0 MB 2.6 MB/s eta 0:00:59\n",
      "   --------------------- ------------------ 178.8/332.0 MB 2.7 MB/s eta 0:00:58\n",
      "   --------------------- ------------------ 179.6/332.0 MB 2.7 MB/s eta 0:00:57\n",
      "   --------------------- ------------------ 180.6/332.0 MB 2.7 MB/s eta 0:00:57\n",
      "   --------------------- ------------------ 181.7/332.0 MB 2.7 MB/s eta 0:00:56\n",
      "   --------------------- ------------------ 182.2/332.0 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------------------- ----------------- 183.0/332.0 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------------------- ----------------- 183.5/332.0 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------------------- ----------------- 184.0/332.0 MB 2.7 MB/s eta 0:00:54\n",
      "   ---------------------- ----------------- 184.5/332.0 MB 2.8 MB/s eta 0:00:54\n",
      "   ---------------------- ----------------- 185.1/332.0 MB 2.8 MB/s eta 0:00:54\n",
      "   ---------------------- ----------------- 185.6/332.0 MB 2.8 MB/s eta 0:00:54\n",
      "   ---------------------- ----------------- 186.4/332.0 MB 2.8 MB/s eta 0:00:53\n",
      "   ---------------------- ----------------- 186.9/332.0 MB 2.8 MB/s eta 0:00:53\n",
      "   ---------------------- ----------------- 187.7/332.0 MB 2.8 MB/s eta 0:00:52\n",
      "   ---------------------- ----------------- 188.5/332.0 MB 2.8 MB/s eta 0:00:52\n",
      "   ---------------------- ----------------- 189.0/332.0 MB 2.8 MB/s eta 0:00:52\n",
      "   ---------------------- ----------------- 189.5/332.0 MB 2.8 MB/s eta 0:00:51\n",
      "   ---------------------- ----------------- 190.1/332.0 MB 2.8 MB/s eta 0:00:51\n",
      "   ---------------------- ----------------- 190.6/332.0 MB 2.8 MB/s eta 0:00:51\n",
      "   ----------------------- ---------------- 191.4/332.0 MB 2.8 MB/s eta 0:00:51\n",
      "   ----------------------- ---------------- 191.9/332.0 MB 2.8 MB/s eta 0:00:50\n",
      "   ----------------------- ---------------- 192.7/332.0 MB 2.8 MB/s eta 0:00:50\n",
      "   ----------------------- ---------------- 193.2/332.0 MB 2.8 MB/s eta 0:00:50\n",
      "   ----------------------- ---------------- 194.0/332.0 MB 2.8 MB/s eta 0:00:50\n",
      "   ----------------------- ---------------- 194.8/332.0 MB 2.8 MB/s eta 0:00:49\n",
      "   ----------------------- ---------------- 195.6/332.0 MB 2.8 MB/s eta 0:00:49\n",
      "   ----------------------- ---------------- 196.1/332.0 MB 2.8 MB/s eta 0:00:49\n",
      "   ----------------------- ---------------- 196.9/332.0 MB 2.8 MB/s eta 0:00:48\n",
      "   ----------------------- ---------------- 197.4/332.0 MB 2.8 MB/s eta 0:00:48\n",
      "   ----------------------- ---------------- 198.2/332.0 MB 2.8 MB/s eta 0:00:48\n",
      "   ----------------------- ---------------- 198.7/332.0 MB 2.8 MB/s eta 0:00:48\n",
      "   ------------------------ --------------- 199.5/332.0 MB 2.8 MB/s eta 0:00:48\n",
      "   ------------------------ --------------- 200.3/332.0 MB 2.8 MB/s eta 0:00:47\n",
      "   ------------------------ --------------- 200.8/332.0 MB 2.8 MB/s eta 0:00:47\n",
      "   ------------------------ --------------- 201.6/332.0 MB 2.8 MB/s eta 0:00:47\n",
      "   ------------------------ --------------- 202.4/332.0 MB 2.8 MB/s eta 0:00:46\n",
      "   ------------------------ --------------- 203.2/332.0 MB 2.8 MB/s eta 0:00:46\n",
      "   ------------------------ --------------- 203.9/332.0 MB 2.8 MB/s eta 0:00:46\n",
      "   ------------------------ --------------- 204.7/332.0 MB 2.9 MB/s eta 0:00:45\n",
      "   ------------------------ --------------- 205.5/332.0 MB 2.9 MB/s eta 0:00:45\n",
      "   ------------------------ --------------- 206.3/332.0 MB 2.9 MB/s eta 0:00:44\n",
      "   ------------------------ --------------- 207.1/332.0 MB 2.9 MB/s eta 0:00:44\n",
      "   ------------------------- -------------- 208.1/332.0 MB 2.9 MB/s eta 0:00:44\n",
      "   ------------------------- -------------- 208.9/332.0 MB 2.9 MB/s eta 0:00:43\n",
      "   ------------------------- -------------- 210.0/332.0 MB 2.9 MB/s eta 0:00:43\n",
      "   ------------------------- -------------- 211.0/332.0 MB 2.9 MB/s eta 0:00:42\n",
      "   ------------------------- -------------- 211.8/332.0 MB 2.9 MB/s eta 0:00:42\n",
      "   ------------------------- -------------- 212.9/332.0 MB 2.9 MB/s eta 0:00:41\n",
      "   ------------------------- -------------- 213.4/332.0 MB 2.9 MB/s eta 0:00:41\n",
      "   ------------------------- -------------- 213.9/332.0 MB 2.9 MB/s eta 0:00:41\n",
      "   ------------------------- -------------- 214.2/332.0 MB 2.9 MB/s eta 0:00:41\n",
      "   ------------------------- -------------- 214.2/332.0 MB 2.9 MB/s eta 0:00:41\n",
      "   ------------------------- -------------- 214.2/332.0 MB 2.9 MB/s eta 0:00:41\n",
      "   ------------------------- -------------- 214.4/332.0 MB 2.9 MB/s eta 0:00:41\n",
      "   ------------------------- -------------- 214.7/332.0 MB 2.9 MB/s eta 0:00:41\n",
      "   ------------------------- -------------- 215.2/332.0 MB 2.9 MB/s eta 0:00:41\n",
      "   ------------------------- -------------- 215.5/332.0 MB 2.9 MB/s eta 0:00:41\n",
      "   ------------------------- -------------- 215.7/332.0 MB 2.9 MB/s eta 0:00:41\n",
      "   -------------------------- ------------- 216.0/332.0 MB 2.9 MB/s eta 0:00:41\n",
      "   -------------------------- ------------- 216.3/332.0 MB 2.9 MB/s eta 0:00:41\n",
      "   -------------------------- ------------- 216.5/332.0 MB 2.9 MB/s eta 0:00:41\n",
      "   -------------------------- ------------- 216.8/332.0 MB 2.9 MB/s eta 0:00:41\n",
      "   -------------------------- ------------- 217.3/332.0 MB 2.9 MB/s eta 0:00:40\n",
      "   -------------------------- ------------- 217.6/332.0 MB 2.9 MB/s eta 0:00:40\n",
      "   -------------------------- ------------- 218.1/332.0 MB 2.9 MB/s eta 0:00:40\n",
      "   -------------------------- ------------- 218.4/332.0 MB 2.9 MB/s eta 0:00:40\n",
      "   -------------------------- ------------- 218.9/332.0 MB 2.9 MB/s eta 0:00:40\n",
      "   -------------------------- ------------- 219.2/332.0 MB 2.9 MB/s eta 0:00:40\n",
      "   -------------------------- ------------- 219.7/332.0 MB 2.9 MB/s eta 0:00:40\n",
      "   -------------------------- ------------- 219.9/332.0 MB 2.9 MB/s eta 0:00:39\n",
      "   -------------------------- ------------- 220.5/332.0 MB 2.9 MB/s eta 0:00:39\n",
      "   -------------------------- ------------- 221.0/332.0 MB 2.9 MB/s eta 0:00:39\n",
      "   -------------------------- ------------- 221.2/332.0 MB 2.9 MB/s eta 0:00:39\n",
      "   -------------------------- ------------- 221.8/332.0 MB 2.9 MB/s eta 0:00:38\n",
      "   -------------------------- ------------- 222.0/332.0 MB 2.9 MB/s eta 0:00:38\n",
      "   -------------------------- ------------- 222.6/332.0 MB 2.9 MB/s eta 0:00:38\n",
      "   -------------------------- ------------- 222.8/332.0 MB 2.9 MB/s eta 0:00:38\n",
      "   -------------------------- ------------- 223.3/332.0 MB 2.9 MB/s eta 0:00:38\n",
      "   -------------------------- ------------- 223.9/332.0 MB 2.9 MB/s eta 0:00:38\n",
      "   --------------------------- ------------ 224.4/332.0 MB 2.9 MB/s eta 0:00:38\n",
      "   --------------------------- ------------ 224.9/332.0 MB 2.9 MB/s eta 0:00:37\n",
      "   --------------------------- ------------ 225.4/332.0 MB 2.9 MB/s eta 0:00:37\n",
      "   --------------------------- ------------ 226.2/332.0 MB 2.9 MB/s eta 0:00:37\n",
      "   --------------------------- ------------ 226.8/332.0 MB 2.9 MB/s eta 0:00:37\n",
      "   --------------------------- ------------ 227.3/332.0 MB 2.9 MB/s eta 0:00:37\n",
      "   --------------------------- ------------ 228.1/332.0 MB 2.9 MB/s eta 0:00:36\n",
      "   --------------------------- ------------ 228.6/332.0 MB 2.9 MB/s eta 0:00:36\n",
      "   --------------------------- ------------ 229.4/332.0 MB 2.9 MB/s eta 0:00:36\n",
      "   --------------------------- ------------ 230.2/332.0 MB 2.9 MB/s eta 0:00:36\n",
      "   --------------------------- ------------ 230.9/332.0 MB 2.9 MB/s eta 0:00:35\n",
      "   --------------------------- ------------ 231.7/332.0 MB 2.9 MB/s eta 0:00:35\n",
      "   --------------------------- ------------ 232.3/332.0 MB 2.9 MB/s eta 0:00:35\n",
      "   ---------------------------- ----------- 233.3/332.0 MB 2.9 MB/s eta 0:00:34\n",
      "   ---------------------------- ----------- 234.1/332.0 MB 2.9 MB/s eta 0:00:34\n",
      "   ---------------------------- ----------- 234.9/332.0 MB 2.9 MB/s eta 0:00:34\n",
      "   ---------------------------- ----------- 235.9/332.0 MB 2.9 MB/s eta 0:00:33\n",
      "   ---------------------------- ----------- 236.7/332.0 MB 2.9 MB/s eta 0:00:33\n",
      "   ---------------------------- ----------- 237.8/332.0 MB 2.9 MB/s eta 0:00:32\n",
      "   ---------------------------- ----------- 238.6/332.0 MB 3.0 MB/s eta 0:00:32\n",
      "   ---------------------------- ----------- 239.6/332.0 MB 3.0 MB/s eta 0:00:32\n",
      "   ---------------------------- ----------- 240.4/332.0 MB 3.0 MB/s eta 0:00:31\n",
      "   ----------------------------- ---------- 241.4/332.0 MB 3.0 MB/s eta 0:00:31\n",
      "   ----------------------------- ---------- 242.7/332.0 MB 3.0 MB/s eta 0:00:30\n",
      "   ----------------------------- ---------- 243.5/332.0 MB 3.0 MB/s eta 0:00:30\n",
      "   ----------------------------- ---------- 244.8/332.0 MB 3.0 MB/s eta 0:00:29\n",
      "   ----------------------------- ---------- 245.9/332.0 MB 3.1 MB/s eta 0:00:29\n",
      "   ----------------------------- ---------- 246.9/332.0 MB 3.1 MB/s eta 0:00:28\n",
      "   ----------------------------- ---------- 248.3/332.0 MB 3.1 MB/s eta 0:00:27\n",
      "   ------------------------------ --------- 249.3/332.0 MB 3.1 MB/s eta 0:00:27\n",
      "   ------------------------------ --------- 250.6/332.0 MB 3.2 MB/s eta 0:00:26\n",
      "   ------------------------------ --------- 251.9/332.0 MB 3.2 MB/s eta 0:00:26\n",
      "   ------------------------------ --------- 253.2/332.0 MB 3.2 MB/s eta 0:00:25\n",
      "   ------------------------------ --------- 254.5/332.0 MB 3.2 MB/s eta 0:00:25\n",
      "   ------------------------------ --------- 255.9/332.0 MB 3.2 MB/s eta 0:00:24\n",
      "   ------------------------------ --------- 257.2/332.0 MB 3.3 MB/s eta 0:00:23\n",
      "   ------------------------------- -------- 258.2/332.0 MB 3.3 MB/s eta 0:00:23\n",
      "   ------------------------------- -------- 259.3/332.0 MB 3.3 MB/s eta 0:00:23\n",
      "   ------------------------------- -------- 260.0/332.0 MB 3.3 MB/s eta 0:00:22\n",
      "   ------------------------------- -------- 260.8/332.0 MB 3.3 MB/s eta 0:00:22\n",
      "   ------------------------------- -------- 261.4/332.0 MB 3.3 MB/s eta 0:00:22\n",
      "   ------------------------------- -------- 262.1/332.0 MB 3.3 MB/s eta 0:00:22\n",
      "   ------------------------------- -------- 262.7/332.0 MB 3.3 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 263.2/332.0 MB 3.3 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 264.0/332.0 MB 3.3 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 264.8/332.0 MB 3.3 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 265.3/332.0 MB 3.3 MB/s eta 0:00:21\n",
      "   -------------------------------- ------- 266.1/332.0 MB 3.3 MB/s eta 0:00:20\n",
      "   -------------------------------- ------- 266.9/332.0 MB 3.3 MB/s eta 0:00:20\n",
      "   -------------------------------- ------- 267.4/332.0 MB 3.3 MB/s eta 0:00:20\n",
      "   -------------------------------- ------- 268.2/332.0 MB 3.3 MB/s eta 0:00:20\n",
      "   -------------------------------- ------- 268.7/332.0 MB 3.3 MB/s eta 0:00:20\n",
      "   -------------------------------- ------- 269.2/332.0 MB 3.3 MB/s eta 0:00:20\n",
      "   -------------------------------- ------- 269.7/332.0 MB 3.3 MB/s eta 0:00:20\n",
      "   -------------------------------- ------- 270.3/332.0 MB 3.2 MB/s eta 0:00:20\n",
      "   -------------------------------- ------- 270.8/332.0 MB 3.2 MB/s eta 0:00:19\n",
      "   -------------------------------- ------- 271.3/332.0 MB 3.2 MB/s eta 0:00:19\n",
      "   -------------------------------- ------- 271.8/332.0 MB 3.2 MB/s eta 0:00:19\n",
      "   -------------------------------- ------- 272.6/332.0 MB 3.2 MB/s eta 0:00:19\n",
      "   -------------------------------- ------- 273.2/332.0 MB 3.2 MB/s eta 0:00:19\n",
      "   -------------------------------- ------- 273.7/332.0 MB 3.2 MB/s eta 0:00:19\n",
      "   --------------------------------- ------ 274.5/332.0 MB 3.2 MB/s eta 0:00:19\n",
      "   --------------------------------- ------ 275.0/332.0 MB 3.2 MB/s eta 0:00:19\n",
      "   --------------------------------- ------ 275.8/332.0 MB 3.2 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 276.6/332.0 MB 3.1 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 277.1/332.0 MB 3.1 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 277.9/332.0 MB 3.2 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 278.9/332.0 MB 3.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 279.4/332.0 MB 3.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 280.0/332.0 MB 3.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 280.8/332.0 MB 3.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 281.3/332.0 MB 3.2 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 282.1/332.0 MB 3.2 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 282.9/332.0 MB 3.2 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 283.4/332.0 MB 3.2 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 284.2/332.0 MB 3.2 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 284.7/332.0 MB 3.2 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 285.2/332.0 MB 3.2 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 286.0/332.0 MB 3.2 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 286.5/332.0 MB 3.2 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 287.3/332.0 MB 3.2 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 287.8/332.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 288.4/332.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 288.9/332.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 289.4/332.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 289.9/332.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ----------------------------------- ---- 290.7/332.0 MB 3.2 MB/s eta 0:00:14\n",
      "   ----------------------------------- ---- 291.2/332.0 MB 3.2 MB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 292.0/332.0 MB 3.2 MB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 292.8/332.0 MB 3.2 MB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 293.3/332.0 MB 3.2 MB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 294.1/332.0 MB 3.2 MB/s eta 0:00:12\n",
      "   ----------------------------------- ---- 294.9/332.0 MB 3.2 MB/s eta 0:00:12\n",
      "   ----------------------------------- ---- 295.7/332.0 MB 3.2 MB/s eta 0:00:12\n",
      "   ----------------------------------- ---- 296.5/332.0 MB 3.2 MB/s eta 0:00:12\n",
      "   ----------------------------------- ---- 297.3/332.0 MB 3.2 MB/s eta 0:00:11\n",
      "   ----------------------------------- ---- 298.1/332.0 MB 3.2 MB/s eta 0:00:11\n",
      "   ------------------------------------ --- 298.8/332.0 MB 3.2 MB/s eta 0:00:11\n",
      "   ------------------------------------ --- 299.9/332.0 MB 3.2 MB/s eta 0:00:11\n",
      "   ------------------------------------ --- 300.9/332.0 MB 3.2 MB/s eta 0:00:10\n",
      "   ------------------------------------ --- 301.7/332.0 MB 3.2 MB/s eta 0:00:10\n",
      "   ------------------------------------ --- 302.8/332.0 MB 3.2 MB/s eta 0:00:10\n",
      "   ------------------------------------ --- 303.6/332.0 MB 3.2 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 304.3/332.0 MB 3.2 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 305.1/332.0 MB 3.2 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 305.9/332.0 MB 3.2 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 306.4/332.0 MB 3.2 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 307.0/332.0 MB 3.2 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 307.8/332.0 MB 3.2 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 308.3/332.0 MB 3.2 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 309.1/332.0 MB 3.2 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 309.9/332.0 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 310.6/332.0 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 311.2/332.0 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 312.0/332.0 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 312.5/332.0 MB 3.3 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 313.0/332.0 MB 3.3 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 313.8/332.0 MB 3.3 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 314.3/332.0 MB 3.3 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 315.1/332.0 MB 3.3 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 315.9/332.0 MB 3.3 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 316.4/332.0 MB 3.3 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 317.2/332.0 MB 3.3 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 318.0/332.0 MB 3.4 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 318.8/332.0 MB 3.4 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 319.6/332.0 MB 3.4 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 320.3/332.0 MB 3.4 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 321.1/332.0 MB 3.4 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 322.2/332.0 MB 3.4 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 323.0/332.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ---------------------------------------  324.0/332.0 MB 3.5 MB/s eta 0:00:03\n",
      "   ---------------------------------------  324.8/332.0 MB 3.5 MB/s eta 0:00:03\n",
      "   ---------------------------------------  325.6/332.0 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  326.6/332.0 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  327.4/332.0 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  328.2/332.0 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  329.0/332.0 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  329.8/332.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  330.8/332.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.6/332.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 332.0/332.0 MB 3.4 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.76.0-cp313-cp313-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.8/4.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.6/4.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.1/4.7 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.9/4.7 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.7/4.7 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.2/4.7 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 3.3 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.4-cp313-cp313-win_amd64.whl (212 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/5.5 MB 2.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.0/5.5 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.6/5.5 MB 2.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.1/5.5 MB 2.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 2.9/5.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.4/5.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.2/5.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.5 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 2.9 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 0.8/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.0/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 2.0 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/26.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/26.4 MB 2.3 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 1.3/26.4 MB 2.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 1.8/26.4 MB 2.3 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 2.1/26.4 MB 2.1 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 2.4/26.4 MB 1.9 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 2.6/26.4 MB 1.9 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 2.9/26.4 MB 1.7 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 2.9/26.4 MB 1.7 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 3.4/26.4 MB 1.6 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 3.7/26.4 MB 1.6 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 3.9/26.4 MB 1.6 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 4.2/26.4 MB 1.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 4.7/26.4 MB 1.6 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 5.2/26.4 MB 1.6 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 5.5/26.4 MB 1.6 MB/s eta 0:00:13\n",
      "   --------- ------------------------------ 6.0/26.4 MB 1.7 MB/s eta 0:00:13\n",
      "   --------- ------------------------------ 6.6/26.4 MB 1.7 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 6.8/26.4 MB 1.7 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 7.3/26.4 MB 1.8 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 8.1/26.4 MB 1.8 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 8.7/26.4 MB 1.9 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 9.2/26.4 MB 1.9 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 10.0/26.4 MB 2.0 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 10.5/26.4 MB 2.0 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 11.3/26.4 MB 2.0 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 11.8/26.4 MB 2.1 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 12.3/26.4 MB 2.1 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 13.1/26.4 MB 2.1 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 13.6/26.4 MB 2.2 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 14.4/26.4 MB 2.2 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 14.9/26.4 MB 2.2 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 15.7/26.4 MB 2.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 16.3/26.4 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 17.0/26.4 MB 2.3 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 17.6/26.4 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 18.1/26.4 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 18.6/26.4 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 19.1/26.4 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 19.9/26.4 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 20.4/26.4 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 21.0/26.4 MB 2.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 21.5/26.4 MB 2.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 22.3/26.4 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 23.1/26.4 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 23.9/26.4 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 24.4/26.4 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.2/26.4 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.0/26.4 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 2.5 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.18.0-cp313-cp313-win_amd64.whl (314 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt_einsum, ml_dtypes, grpcio, google_pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "\n",
      "   -- -------------------------------------  1/16 [libclang]\n",
      "   -- -------------------------------------  1/16 [libclang]\n",
      "   -- -------------------------------------  1/16 [libclang]\n",
      "   ----- ----------------------------------  2/16 [flatbuffers]\n",
      "   ------------ ---------------------------  5/16 [optree]\n",
      "   --------------- ------------------------  6/16 [opt_einsum]\n",
      "   ----------------- ----------------------  7/16 [ml_dtypes]\n",
      "   -------------------- -------------------  8/16 [grpcio]\n",
      "   -------------------- -------------------  8/16 [grpcio]\n",
      "   -------------------- -------------------  8/16 [grpcio]\n",
      "   ------------------------- -------------- 10/16 [gast]\n",
      "   ------------------------------ --------- 12/16 [absl-py]\n",
      "   ------------------------------ --------- 12/16 [absl-py]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ---------------------------------------- 16/16 [tensorflow]\n",
      "\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 grpcio-1.76.0 keras-3.12.0 libclang-18.1.1 ml_dtypes-0.5.4 namex-0.1.0 opt_einsum-3.4.0 optree-0.18.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e45ed83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6500 - loss: 0.8622\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6500 - loss: 0.7816 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6500 - loss: 0.7483 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6500 - loss: 0.7134 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6500 - loss: 0.6829 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6500 - loss: 0.6561 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6500 - loss: 0.6292 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6500 - loss: 0.6050 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6667 - loss: 0.5815 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7250 - loss: 0.5628 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7250 - loss: 0.5440 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7000 - loss: 0.5273 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7167 - loss: 0.5122 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7083 - loss: 0.5041 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8083 - loss: 0.4868 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8833 - loss: 0.4763 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.4661 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8750 - loss: 0.4575 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9083 - loss: 0.4489 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9000 - loss: 0.4389 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.4354 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9167 - loss: 0.4338 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9250 - loss: 0.4173 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8833 - loss: 0.4110 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9250 - loss: 0.4039 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8333 - loss: 0.4123 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9333 - loss: 0.3922 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9500 - loss: 0.3860 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9500 - loss: 0.3801\n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9333 - loss: 0.3723 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9333 - loss: 0.3741 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9333 - loss: 0.3602 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9167 - loss: 0.3569 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9750 - loss: 0.3472\n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.3438 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9583 - loss: 0.3376 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9500 - loss: 0.3367 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9583 - loss: 0.3280 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9583 - loss: 0.3259 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.3157 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.3098 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.3034 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9750 - loss: 0.2976 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.2962 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.2875 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9750 - loss: 0.2808 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.2763 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.2777 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9750 - loss: 0.2649 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.2629 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9333 - loss: 0.2675\n",
      "Akurasi: 0.9333333373069763\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.reshape(-1, 1)\n",
    "\n",
    "# One-hot encoding\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Bangun model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Kompilasi\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Latih model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=8)\n",
    "\n",
    "# Evaluasi\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Akurasi: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae886b2f",
   "metadata": {},
   "source": [
    "### Tugas 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e72eb2",
   "metadata": {},
   "source": [
    "1. Ubah jumlah neuron hidden layer.\n",
    "2. Bandingkan akurasi dengan konfigurasi awal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c326a934",
   "metadata": {},
   "source": [
    "Model awal (hidden 1: 10, Hidden 2: 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c7c2ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3417 - loss: 2.1883\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3417 - loss: 1.5914 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3417 - loss: 1.1717 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3417 - loss: 0.9465 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5583 - loss: 0.8745 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6500 - loss: 0.8323 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6583 - loss: 0.8060 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6583 - loss: 0.7743 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6583 - loss: 0.7471 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6583 - loss: 0.7239 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6750 - loss: 0.6974 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6750 - loss: 0.6725 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6750 - loss: 0.6493 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6750 - loss: 0.6295 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.6117 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7333 - loss: 0.5905 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7250 - loss: 0.5734 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7500 - loss: 0.5577 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7833 - loss: 0.5449 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.5300 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8000 - loss: 0.5159 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.5079 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7833 - loss: 0.5000 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8667 - loss: 0.4864 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8583 - loss: 0.4735 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.4633 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8583 - loss: 0.4548\n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8500 - loss: 0.4457 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8917 - loss: 0.4386 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.4318 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9000 - loss: 0.4211 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9333 - loss: 0.4146 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9250 - loss: 0.4105 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.4044 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9083 - loss: 0.3969 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9083 - loss: 0.3864 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.3801 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.3750 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9000 - loss: 0.3726 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.3607 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.3547 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.3491 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9250 - loss: 0.3423 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9500 - loss: 0.3359 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.3357 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9750 - loss: 0.3268 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.3178 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9500 - loss: 0.3148 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.3087 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.3016 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9667 - loss: 0.2454\n",
      "Akurasi Baseline: 0.9666666388511658\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=8)\n",
    "loss_base, acc_base = model.evaluate(X_test, y_test)\n",
    "print(\"Akurasi Baseline:\", acc_base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820bea1b",
   "metadata": {},
   "source": [
    "Model 2: Hidden 6 & 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12a0afc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3333 - loss: 1.4673\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3333 - loss: 1.3326 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3333 - loss: 1.2348 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3333 - loss: 1.1578 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3333 - loss: 1.1052 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3333 - loss: 1.0717 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3333 - loss: 1.0492 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3583 - loss: 1.0279 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5417 - loss: 1.0072\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6750 - loss: 0.9877 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8000 - loss: 0.9685 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7583 - loss: 0.9541 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7417 - loss: 0.9424 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7417 - loss: 0.9318 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7333 - loss: 0.9207 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7250 - loss: 0.9099 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7250 - loss: 0.8990 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.8872 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7167 - loss: 0.8756 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7083 - loss: 0.8656\n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7167 - loss: 0.8515 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.8392 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7250 - loss: 0.8276 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7167 - loss: 0.8151 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.8019 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.7895\n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7500 - loss: 0.7765 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7750 - loss: 0.7652 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8000 - loss: 0.7518 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8000 - loss: 0.7411 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8250 - loss: 0.7274 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8417 - loss: 0.7158 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8417 - loss: 0.7044 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8417 - loss: 0.6929 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8333 - loss: 0.6820 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8167 - loss: 0.6713 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7917 - loss: 0.6613 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8083 - loss: 0.6500 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7917 - loss: 0.6406 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8000 - loss: 0.6320 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7917 - loss: 0.6210 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7917 - loss: 0.6120 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7750 - loss: 0.6026 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.5942 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7583 - loss: 0.5855 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7583 - loss: 0.5755\n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7583 - loss: 0.5682 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7417 - loss: 0.5600 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7583 - loss: 0.5519 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7667 - loss: 0.5441 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.8333 - loss: 0.5335\n",
      "Akurasi Model A: 0.8333333134651184\n"
     ]
    }
   ],
   "source": [
    "modelA = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(6, activation='relu', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "modelA.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "modelA.fit(X_train, y_train, epochs=50, batch_size=8)\n",
    "loss_A, acc_A = modelA.evaluate(X_test, y_test)\n",
    "print(\"Akurasi Model A:\", acc_A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8e3492",
   "metadata": {},
   "source": [
    "Model 3: Hidden lebih besar (16 & 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "180b73ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3333 - loss: 1.5247   \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3333 - loss: 1.2271 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5000 - loss: 1.0324 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6500 - loss: 0.9097 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6500 - loss: 0.8517 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6750 - loss: 0.8055 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7667 - loss: 0.7635 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6833 - loss: 0.7256 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8000 - loss: 0.6821 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8417 - loss: 0.6397 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8083 - loss: 0.6041\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7750 - loss: 0.5737 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9250 - loss: 0.5445 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9333 - loss: 0.5177 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8417 - loss: 0.5008 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9417 - loss: 0.4772 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9583 - loss: 0.4636\n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9750 - loss: 0.4449 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9750 - loss: 0.4318 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.4242 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9750 - loss: 0.4074\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9250 - loss: 0.4028 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.3880 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9833 - loss: 0.3807\n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.3727 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.3650 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9333 - loss: 0.3631 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.3515 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.3446 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9250 - loss: 0.3449 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.3315 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.3254 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9750 - loss: 0.3206 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.3126 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9833 - loss: 0.3093\n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.3026 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.2972 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.2915 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.2900 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.2816 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.2795 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.2709 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.2672 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.2649 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.2557 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.2553 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.2438 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9750 - loss: 0.2446 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9583 - loss: 0.2440 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9833 - loss: 0.2350 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9333 - loss: 0.2232\n",
      "Akurasi Model B: 0.9333333373069763\n"
     ]
    }
   ],
   "source": [
    "modelB = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='relu', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(12, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "modelB.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "modelB.fit(X_train, y_train, epochs=50, batch_size=8)\n",
    "loss_B, acc_B = modelB.evaluate(X_test, y_test)\n",
    "print(\"Akurasi Model B:\", acc_B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c01c1d",
   "metadata": {},
   "source": [
    "Berdasarkan hasil tersebut, yakni:\n",
    "- Model awal (hidden 10 & 8) menghasilkan akurasi 0.966...\n",
    "- Model kedua (hidden 6 & 4) menghasilkan akurasi 0.833...\n",
    "- Model ketiga (hidden 16 & 12) menghasilkan akurasi 0.933...\n",
    "Sehingga dapat disimpulkan bahwa model awal merupakan model terbaik untuk kasus ini, karena jika menggunakan layer lebih kecil / lebih besar hasil akurasinya menurun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8771d06",
   "metadata": {},
   "source": [
    "### Tugas 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9704e91",
   "metadata": {},
   "source": [
    "Model reLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22389a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3167 - loss: 1.3448   \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3000 - loss: 1.2837 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2250 - loss: 1.2317 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1833 - loss: 1.1930 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3333 - loss: 1.1561  \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3333 - loss: 1.1276     \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3583 - loss: 1.1053 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3333 - loss: 1.0810 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3167 - loss: 1.0586 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4083 - loss: 1.0376 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4750 - loss: 1.0156 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6333 - loss: 0.9939 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6500 - loss: 0.9624 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6500 - loss: 0.9334 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6500 - loss: 0.9051 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6500 - loss: 0.8706 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6500 - loss: 0.8373 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6833 - loss: 0.7958 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7167 - loss: 0.7624 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7750 - loss: 0.7357 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7917 - loss: 0.7092 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8250 - loss: 0.6827 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8917 - loss: 0.6559 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9333 - loss: 0.6298 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.6041 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9333 - loss: 0.5801 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9500 - loss: 0.5528 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.5280 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.5042 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9667 - loss: 0.4842\n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.4627 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.4428 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9750 - loss: 0.4231 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.4038 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.3909 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.3792 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.3576 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.3427 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.3296 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.3167 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.3052 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.2916 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.2824 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.2692 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.2591 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.2478 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.2394 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.2268 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.2196 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.2101 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.9667 - loss: 0.1848\n",
      "Akurasi Baseline: 0.9666666388511658\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=8)\n",
    "loss_base, acc_base = model.evaluate(X_test, y_test)\n",
    "print(\"Akurasi Baseline:\", acc_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568a30a1",
   "metadata": {},
   "source": [
    "Model Sigmoid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3027fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3500 - loss: 1.1382\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3500 - loss: 1.1185 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3500 - loss: 1.1058 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3500 - loss: 1.0936\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3500 - loss: 1.0847 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3500 - loss: 1.0787 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3500 - loss: 1.0742 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3500 - loss: 1.0684 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3500 - loss: 1.0635 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3583 - loss: 1.0584 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3500 - loss: 1.0548 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3667 - loss: 1.0489 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4917 - loss: 1.0435 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5750 - loss: 1.0382 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6750 - loss: 1.0320 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6750 - loss: 1.0259 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6833 - loss: 1.0190 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6833 - loss: 1.0125  \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7000 - loss: 1.0039 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7833 - loss: 0.9957 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7917 - loss: 0.9875 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9000 - loss: 0.9779 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.9681 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.9587 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9250 - loss: 0.9477 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9417 - loss: 0.9360 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.9243 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9333 - loss: 0.9131 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9000 - loss: 0.8999 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8917 - loss: 0.8868 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8583 - loss: 0.8739 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8833 - loss: 0.8603 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8917 - loss: 0.8466 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8583 - loss: 0.8324 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8417 - loss: 0.8183 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8583 - loss: 0.8044 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8417 - loss: 0.7907 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8583 - loss: 0.7760 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8583 - loss: 0.7623 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8583 - loss: 0.7478 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8583 - loss: 0.7341 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8667 - loss: 0.7204 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8667 - loss: 0.7071 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.6941 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.6813 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.6694 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8667 - loss: 0.6572 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.6457 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.6351 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8583 - loss: 0.6261 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.8667 - loss: 0.5978\n",
      "Akurasi Sigmoid: 0.8666666746139526\n"
     ]
    }
   ],
   "source": [
    "model_sigmoid = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='sigmoid', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(8, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_sigmoid.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_sigmoid.fit(X_train, y_train, epochs=50, batch_size=8)\n",
    "\n",
    "loss_sig, acc_sig = model_sigmoid.evaluate(X_test, y_test)\n",
    "print(\"Akurasi Sigmoid:\", acc_sig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2303617",
   "metadata": {},
   "source": [
    "Berdasarkan hasil tersebut, dapat disimpulkan bahwa model aktivasi reLU menghasilkan loss lebih sedikit dengan akurasi lebih tinggi. Sehingga model aktivasi reLU lebih cocok digunakan untuk kasus ini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822a2d4b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
